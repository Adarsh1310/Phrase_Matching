{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence, stopwords=False):\n",
    "    import re\n",
    "    import gensim \n",
    "    from gensim.parsing.preprocessing import remove_stopwords\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    #sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    \n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "    #sent_stemmed='';\n",
    "    #for word in sentence.split():\n",
    "    #    sent_stemmed+=' '+st.stem(word) \n",
    "    #sentence=sent_stemmed\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence, stopwords=False):\n",
    "    import re\n",
    "    import gensim \n",
    "    from gensim.parsing.preprocessing import remove_stopwords\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    #sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    \n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "    #sent_stemmed='';\n",
    "    #for word in sentence.split():\n",
    "    #    sent_stemmed+=' '+st.stem(word) \n",
    "    #sentence=sent_stemmed\n",
    "    \n",
    "    return sentence\n",
    "def phrase_matching(sentence):\n",
    "    from laserembeddings import Laser\n",
    "    import pandas as pd\n",
    "    from scipy.spatial.distance import cosine\n",
    "    laser=Laser()\n",
    "    data=pd.read_csv(\"FAQ_MachineLearningInterview_com.csv\")\n",
    "    l=[]\n",
    "    for i in data['FAQ Questions from MachineLearningInterview.com']:\n",
    "        l.append(laser.embed_sentences([i],lang='en'))\n",
    "    sen1=sentence\n",
    "    sen_embed=(laser.embed_sentences([sen1],lang='en'))\n",
    "    m=0\n",
    "    for i in range(len(data['FAQ Questions from MachineLearningInterview.com'])):\n",
    "        cosine_sim_0_1 = 1 - cosine(sen_embed, l[i])\n",
    "        if cosine_sim_0_1>m:\n",
    "            m=cosine_sim_0_1\n",
    "            sen=data['FAQ Questions from MachineLearningInterview.com'][i]\n",
    "            pos=i\n",
    "    from langdetect import detect\n",
    "    from googletrans import Translator\n",
    "    def detect_and_translate(text,result_lang):\n",
    "        #result_lang = detect(text)\n",
    "        translator = Translator()\n",
    "        return translator.translate(text,src='en',dest=result_lang).text\n",
    "    result_lang = detect(sen1)\n",
    "    return(detect_and_translate(data['FAQ Answers from MachineLearningInterview.com'][i],result_lang))\n",
    "from flask import Flask,request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "   return \"Hemlo Guys\"\n",
    "\n",
    "@app.route(\"/temp\")\n",
    "def ps():\n",
    "    sequence=\"\"\n",
    "    try:\n",
    "      f = request.files['file']\n",
    "      filename = secure_filename(f.filename)\n",
    "      print(filename)\n",
    "      f.save(os.path.join('',filename))\n",
    "      f_path=os.path.join(\"\",filename)\n",
    "      with open(f_path,'r') as df:\n",
    "        text=df.read()\n",
    "      sequence=text\n",
    "    except:\n",
    "      sequence = request.args['sq']\n",
    "    finally:\n",
    "        ans=phrase_matching(sequence)\n",
    "        return {'answer':ans}\n",
    "if __name__=='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Needs to be reasonably proficient. Again, a data scientist is a developer ++. Usually expected to have the basic skills a developer has including understanding algorithms and data structures and being able to write clean, understable, efficient, well documented code.\\n\\nIn many cases, the data scientist is expected to write production ready code and be able to understand the deployment process. In some cases, the coding could be for decision support.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0rc1\n",
    "phrase_matching(\"Should I study algorithms or data structures for the interview?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "   return \"Hemlo Guys\"\n",
    "\n",
    "@app.route(\"/temp\")\n",
    "def ps():\n",
    "    sequence=\"\"\n",
    "    try:\n",
    "      f = request.files['file']\n",
    "      filename = secure_filename(f.filename)\n",
    "      print(filename)\n",
    "      f.save(os.path.join('',filename))\n",
    "      f_path=os.path.join(\"\",filename)\n",
    "      with open(f_path,'r') as df:\n",
    "        text=df.read()\n",
    "      sequence=text\n",
    "    except:\n",
    "      sequence = request.args['sq']\n",
    "    finally:\n",
    "        ans=phrase_matching(sequence)\n",
    "        return {'answer':ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Feb/2022 20:10:45] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Feb/2022 20:10:50] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Feb/2022 20:11:11] \"\u001b[37mGET /temp?sq=how+many+rounds+are+there+in+the+interview?%22 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
